# Video-to-Guide Pipeline

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-yellow.svg)](https://opensource.org/licenses/Apache-2.0)

A comprehensive toolkit for transforming instructional videos into professional documentation guides through automated transcription and AI-assisted guide generation.

## ğŸ¯ Overview

This pipeline automates the process of converting video content into structured, searchable documentation. Perfect for technical teams, content creators, and organizations looking to scale their documentation processes.

### **Complete Workflow:**
```
ğŸ“¹ Video Files â†’ ğŸµ Audio Extraction â†’ ğŸ“ Transcription â†’ ğŸ“š Guide Generation
```

## âœ¨ Features

- **ğŸµ High-Quality Audio Extraction** - FFmpeg-powered audio extraction optimized for speech recognition
- **ğŸ¤– Accurate Transcription** - OpenAI Whisper integration for precise speech-to-text conversion
- **ğŸ“‹ Template-Based Guide Generation** - Structured markdown guide creation with customizable templates
- **âš¡ Batch Processing** - Process multiple videos simultaneously
- **ğŸ”§ Configurable Pipeline** - YAML-based configuration for different use cases
- **ğŸ“Š Quality Assurance** - Built-in tools for reviewing and validating output
- **ğŸ³ Docker Support** - Containerized deployment for consistent environments

## ğŸ—ï¸ Architecture

### **Two-Stage Processing Pipeline**

This pipeline combines AI-powered transcription with intelligent text processing for **privacy, cost-efficiency, and offline capability**:

#### **Stage 1: Speech-to-Text (OpenAI Whisper - LOCAL)**
- **Technology**: OpenAI's open-source Whisper model
- **Execution**: Runs **locally on your machine** (no API calls)
- **Cost**: **$0.00** - completely free after initial setup
- **Privacy**: All audio processing happens offline
- **Models Available**: 
  - `tiny` - Fastest, basic accuracy (~39 MB)
  - `base` - Good balance of speed/accuracy (~74 MB) **[Default]**
  - `small` - Better accuracy (~244 MB)
  - `medium` - High accuracy (~769 MB)
  - `large` - Best accuracy (~1550 MB)

#### **Stage 2: Guide Generation (Template-Based Processing)**
- **Technology**: Template-based text processing using Jinja2
- **Method**: Intelligent pattern matching and structured formatting
- **Processing**: 
  - Extracts sections using natural language patterns
  - Identifies commands with shell syntax recognition
  - Finds URLs using regex validation
  - Structures content using template engines
- **Templates**: Customizable Markdown templates with structured formatting

### **Key Architectural Benefits**

| Aspect | Traditional API Approach | Our Architecture |
|--------|--------------------------|------------------|
| **Cost** | $0.10-$1.00+ per hour of audio | **$0.00** |
| **Privacy** | Audio sent to external servers | **100% local processing** |
| **Reliability** | Depends on internet/API availability | **Works offline** |
| **Speed** | Network latency + processing | **Local GPU/CPU only** |
| **Customization** | Limited by API constraints | **Full model control** |

### **Hardware Requirements**

- **CPU Processing**: Works on any modern CPU (slower)
- **GPU Acceleration**: CUDA-compatible GPU recommended for faster processing
- **RAM Requirements**:
  - `tiny/base` models: 2-4GB RAM
  - `small/medium` models: 4-8GB RAM  
  - `large` models: 8GB+ RAM
- **Storage**: 100MB - 2GB for model files (downloaded once)

### **No External Dependencies**

âœ… **No API keys required**  
âœ… **No internet connection needed** (after initial setup)  
âœ… **No external service accounts**  
âœ… **No usage limits or quotas**  
âœ… **Complete data privacy**  

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- FFmpeg installed on your system
- 4GB+ RAM (for Whisper models)

### Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/mik-tf/video-to-guide-pipeline.git
   cd video-to-guide-pipeline
   ```

2. **Set up the environment:**
   ```bash
   ./scripts/setup_environment.sh
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

### Basic Usage

1. **Place your videos in the `videos/` directory**

2. **Run the complete pipeline:**
   ```bash
   python scripts/process_videos.py --config config/default.yaml
   ```

3. **Find your generated guides in `output/guides/`**

## ğŸ“ Project Structure

```
video-to-guide-pipeline/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .gitignore                  # Git ignore rules
â”œâ”€â”€ .env.example                # Environment variables template
â”œâ”€â”€ docker-compose.yml          # Docker setup
â”œâ”€â”€ Dockerfile                  # Container definition
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ default.yaml            # Default configuration
â”‚   â””â”€â”€ templates.yaml          # Template configurations
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ audio_extractor.py      # FFmpeg audio extraction
â”‚   â”œâ”€â”€ transcriber.py          # Whisper transcription
â”‚   â”œâ”€â”€ guide_generator.py      # Guide creation logic
â”‚   â”œâ”€â”€ template_engine.py      # Template processing
â”‚   â””â”€â”€ utils.py                # Common utilities
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ process_videos.py       # Main processing script
â”‚   â”œâ”€â”€ setup_environment.sh    # Environment setup
â”‚   â””â”€â”€ validate_output.py      # Quality assurance
â”‚
â”œâ”€â”€ videos/                     # Input video files
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ audio/                  # Generated audio files
â”‚   â”œâ”€â”€ transcriptions/         # Text transcriptions
â”‚   â””â”€â”€ guides/                 # Final markdown guides
â”‚
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ deployment_guide.md     # Deployment guide template
â”‚   â”œâ”€â”€ tutorial.md             # Tutorial template
â”‚   â””â”€â”€ api_documentation.md    # API docs template
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_audio_extractor.py
â”‚   â”œâ”€â”€ test_transcriber.py
â”‚   â””â”€â”€ test_guide_generator.py
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ usage.md                # Detailed usage guide
    â”œâ”€â”€ configuration.md        # Configuration options
    â”œâ”€â”€ templates.md            # Template customization
    â””â”€â”€ api.md                  # API documentation
```

## ğŸ”§ Configuration

The pipeline uses YAML configuration files for customization:

```yaml
# config/default.yaml
audio:
  sample_rate: 16000
  channels: 1
  format: "wav"

transcription:
  model: "base"  # tiny, base, small, medium, large
  language: "en"

guide_generation:
  template: "deployment_guide"
  include_timestamps: false
  max_section_length: 500
```

### **AI Model Configuration**

The pipeline's AI components are fully configurable:

```yaml
# Whisper Model Settings
transcription:
  model: "base"              # Model size: tiny, base, small, medium, large
  device: "cpu"              # Processing: cpu, cuda (GPU acceleration)
  language: "en"             # Target language (auto-detect if null)
  temperature: 0.0           # Sampling randomness (0.0 = deterministic)
  beam_size: 5               # Search breadth for accuracy
  fp16: false                # Half-precision (GPU only, faster)

# Guide Processing (Template-Based)
guide_generation:
  extract_commands: true     # Find shell commands automatically
  extract_urls: true         # Identify and validate URLs
  format_code_blocks: true   # Auto-format code snippets
  auto_generate_toc: true    # Create table of contents
```

**Model Selection Guide:**
- **Production**: Use `base` or `small` for best speed/accuracy balance
- **High Accuracy**: Use `medium` or `large` for technical content
- **Fast Processing**: Use `tiny` for quick drafts or testing
- **GPU Available**: Enable `fp16: true` and `device: "cuda"` for 2x speed boost

## ğŸ“– Usage Examples

### Process a Single Video
```bash
python scripts/process_videos.py --input videos/tutorial.mp4 --template deployment_guide
```

### Batch Process Multiple Videos
```bash
python scripts/process_videos.py --batch --config config/batch_processing.yaml
```

### Custom Template
```bash
python scripts/process_videos.py --input videos/demo.mp4 --template custom --template-file templates/my_template.md
```

## ğŸ¯ Use Cases

- **ğŸ“š Technical Documentation** - Convert deployment videos into step-by-step guides
- **ğŸ“ Training Materials** - Transform training videos into searchable documentation
- **ğŸ“‹ Process Documentation** - Document complex procedures from video demonstrations
- **ğŸ”„ Knowledge Transfer** - Preserve institutional knowledge from video content
- **ğŸ“ Content Repurposing** - Convert video content into multiple documentation formats

## ğŸ› ï¸ Advanced Features

### Custom Templates
Create your own guide templates by extending the base template system. See [docs/templates.md](docs/templates.md) for details.

### Quality Assurance
Built-in validation tools help ensure transcription accuracy and guide completeness:
```bash
python scripts/validate_output.py --check-transcription --check-guides
```

### Docker Deployment
Run the entire pipeline in a containerized environment:
```bash
docker-compose up --build
```

## ğŸ“„ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **OpenAI Whisper** - For excellent speech recognition capabilities
- **FFmpeg** - For robust audio/video processing